{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RGB Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toyo97/rgbd-domain-adaptation/blob/master/RGB_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_ErvW7FxArb",
        "colab_type": "text"
      },
      "source": [
        "**Setup**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5amxwn1SQAdw",
        "colab_type": "code",
        "outputId": "a200f7b2-c584-4c38-c34e-728ac90a9db5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\", force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47aNXl1CQyVC",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Crqbu0W3Qxey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.utils.data.dataset import random_split\n",
        "from torch.backends import cudnn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uprTTScV8gaE",
        "colab_type": "text"
      },
      "source": [
        "# File loading\n",
        "Get datasets and Python classes from Github repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baRCjv11ocqL",
        "colab_type": "code",
        "outputId": "e535cdd2-7524-459e-9331-b5620f329727",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "\n",
        "read_drive = False\n",
        "if read_drive:\n",
        "\n",
        "  drive.mount(\"/content/drive/\", force_remount=True)\n",
        "  !unzip -q \"drive/My Drive/MLDL2020/ROD.zip\" -d \"rgbd\"\n",
        "  !unzip -q \"drive/My Drive/MLDL2020/synROD.zip\" -d \"rgbd\"\n",
        "  !cp \"drive/My Drive/MLDL2020/rod-split_sync.txt\" -d \"rgbd/ROD\"\n",
        "  !apt install subversion\n",
        "  !svn checkout https://github.com/toyo97/rgbd-domain-adaptation/trunk/modules\n",
        "\n",
        "else:\n",
        "  if not os.path.isdir('./rgbd'):\n",
        "    user = input('User name: ')\n",
        "    password = getpass('Password: ')\n",
        "    password = urllib.parse.quote(password)\n",
        "\n",
        "    cmd_string = 'git clone https://{0}:{1}@github.com/toyo97/rgbd-domain-adaptation.git'.format(user, password)\n",
        "\n",
        "    os.system(cmd_string)\n",
        "    cmd_string, password = \"\", \"\" # removing the password from the variable\n",
        "    !mv rgbd-domain-adaptation rgbd\n",
        "    !mkdir modules\n",
        "    !cp -r rgbd/modules/ modules/\n",
        "  else:\n",
        "    # update code changes\n",
        "    !git -C rgbd/ pull\n",
        "    !cp -ur rgbd/modules/ modules/\n",
        "\n",
        "DATA_DIR = 'rgbd'"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BeFDUKaDXk6",
        "colab_type": "text"
      },
      "source": [
        "# Datasets\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qrBN4q8RfLF",
        "colab_type": "text"
      },
      "source": [
        "## Data processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS0OfkPoQjY8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imgnet_mean, imgnet_std = (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLgql-aVDXRA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transform = transforms.Compose([ transforms.Resize((256,256)),\n",
        "                                      transforms.RandomCrop(224), # random crop for training\n",
        "                                      transforms.ToTensor(),                                     \n",
        "                                      transforms.Normalize( mean=imgnet_mean, # ImageNet mean and std\n",
        "                                                            std=imgnet_std)]\n",
        ")\n",
        "\n",
        "val_transform = transforms.Compose([ transforms.Resize((256,256)),\n",
        "                                    transforms.CenterCrop(224),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize( mean=imgnet_mean,\n",
        "                                                          std=imgnet_std)]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3y-GYnnv2bH0",
        "colab_type": "code",
        "outputId": "1a47dc1c-6344-44ba-e6b7-2c17c7067a1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from modules.datasets import synROD, ROD\n",
        "\n",
        "source_train_dataset = synROD(DATA_DIR, RAM=False, split=\"train\", transform = train_transform)\n",
        "source_test_dataset = synROD(DATA_DIR, RAM=False, split=\"test\", transform = val_transform)\n",
        "target_dataset = ROD(DATA_DIR, RAM = False, transform=val_transform)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 37528/37528 [00:00<00:00, 154305.69it/s]\n",
            "100%|██████████| 7302/7302 [00:00<00:00, 199859.10it/s]\n",
            "100%|██████████| 32476/32476 [00:00<00:00, 196179.11it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOrW18rDVSjo",
        "colab_type": "text"
      },
      "source": [
        "## Rotation transformation\n",
        "\n",
        "Source: https://pytorch.org/docs/stable/torchvision/transforms.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KpAZgABbhFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision.transforms.functional as TF\n",
        "from torchvision import transforms\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "class UnNormalize(object):\n",
        "    def __init__(self, mean, std):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
        "        Returns:\n",
        "            Tensor: Normalized image.\n",
        "        \"\"\"\n",
        "        new_tensor = torch.empty(tensor.size())\n",
        "        for i, t, m, s in zip(range(3), tensor, self.mean, self.std):\n",
        "            new_tensor[i,:,:] = t.mul(s).add(m)\n",
        "\n",
        "        return new_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoR2m0QG7XAq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def coupled_rotation(image_tuple): # first img in tuple is RGB\n",
        "\n",
        "  j = random.randint(0,3)\n",
        "  k = random.randint(0,3)\n",
        "\n",
        "  z = (k-j) % 4\n",
        "\n",
        "  # Note: TF.rotate is counter-clockwise\n",
        "  rotated_image_tuple = TF.rotate(image_tuple[0], 270*j), TF.rotate(image_tuple[1], 270*k)\n",
        "\n",
        "  return rotated_image_tuple, z\n",
        "\n",
        "\n",
        "def transform_batch(rgb_batch, depth_batch):\n",
        "  \"\"\"\n",
        "  params: both rgb_batch and depth_batch are tensors of shape (BATCH_SIZE, 3, 224, 224)\n",
        "  \"\"\"\n",
        "\n",
        "    # F: from normalized tensor, to unnormalized PIL image\n",
        "  F = transforms.Compose([\n",
        "                            UnNormalize(imgnet_mean, imgnet_std),\n",
        "                            transforms.ToPILImage()\n",
        "  ])\n",
        "    # G: inverseF\n",
        "  G = transforms.Compose([\n",
        "                          transforms.ToTensor(),\n",
        "                          transforms.Normalize(imgnet_mean, imgnet_std)\n",
        "  ])\n",
        "\n",
        "  # New batches with rotation labels\n",
        "  new_rgb_batch = torch.empty(rgb_batch.size())\n",
        "  new_depth_batch = torch.empty(depth_batch.size())\n",
        "  labels = torch.empty(rgb_batch.size()[0], dtype=torch.long)\n",
        "\n",
        "  for i in range(rgb_batch.size()[0]):\n",
        "    # denormalize and back to PIL image\n",
        "    rotated_images, labels[i] = coupled_rotation((F(rgb_batch[i,:,:,:]), F(depth_batch[i,:,:,:])))\n",
        "    new_rgb_batch[i,:,:,:], new_depth_batch[i,:,:,:] = G(rotated_images[0]), G(rotated_images[1])\n",
        "\n",
        "  return new_rgb_batch, new_depth_batch, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yoxrk68AATTE",
        "colab_type": "text"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EzWNsETASIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "NUM_CLASSES = 47\n",
        "\n",
        "NUM_EPOCHS = 3\n",
        "\n",
        "LR = 10e-3\n",
        "MOMENTUM = 0.9\n",
        "STEP_SIZE = 10\n",
        "GAMMA = 0.1\n",
        "# TODO see if batch size should be different for main and pretext\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "LAMBDA = 0.1 # weights contribution of the pretext loss to the total objective\n",
        "ENTROPY_WEIGHT = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9G31FYBDpnD",
        "colab_type": "text"
      },
      "source": [
        "# Prepare dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUzdv9ViDp7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "# Data loaders for synROD - MAIN/PRETEXT task only at training\n",
        "source_dataloader = DataLoader(source_train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
        "\n",
        "# Data loader for ROD train and test - PRETEXT at train, MAIN at test (check validity of drop last when testing)\n",
        "target_dataloader = DataLoader(target_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ai6alsD7xEY",
        "colab_type": "text"
      },
      "source": [
        "# Prepare Network\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qksE6YW67wjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from modules.net import Net\n",
        "net = Net(NUM_CLASSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16F_47pgAL5D",
        "colab_type": "text"
      },
      "source": [
        "# Prepare training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1M9mcA8Kg_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def entropy_loss(p_softmax):\n",
        "    # p_softmax = F.softmax(logits, dim=1)\n",
        "    mask = p_softmax.ge(0.000001)  # greater or equal to, used for numerical stability\n",
        "    mask_out = torch.masked_select(p_softmax, mask)\n",
        "    entropy = -(torch.sum(mask_out * torch.log(mask_out)))\n",
        "    return entropy / float(p_softmax.size(0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCC70aLyUl7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultipleOptimizer(object):\n",
        "    def __init__(self, *op):\n",
        "        self.optimizers = op\n",
        "\n",
        "    def zero_grad(self):\n",
        "        for op in self.optimizers:\n",
        "            op.zero_grad()\n",
        "# random crop for training\n",
        "    def step(self):\n",
        "        for op in self.optimizers:\n",
        "            op.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zg31W3wyALZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "# Define loss\n",
        "# Both main and pretext losses are computed with the cross entropy function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define optimizer\n",
        "# TODO try with different optimizers for the three components of the network\n",
        "optimizer = optim.SGD(net.parameters(), lr=LR, momentum=MOMENTUM)\n",
        "\n",
        "# Define scheduler\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzdtn8CURNkc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the number of iterations\n",
        "# Largest dataset rules\n",
        "NUM_ITER = max(len(source_train_dataset), len(target_dataset)) // BATCH_SIZE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyQxsPE4KxGh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dff11e96-f28a-4ef2-aa74-1bb0259e9ef1"
      },
      "source": [
        "len(source_train_dataset), len(target_dataset)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37528, 32476)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFGMEeFptX3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Allow iterating over a dataset more than once\n",
        "# to deal with different number of samples between datasets\n",
        "# during training and batch sampling\n",
        "def loopy(dl):\n",
        "  while True:\n",
        "    for x in dl: yield x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMpWTy3G2OD2",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtxtRsdLhA8d",
        "colab_type": "code",
        "outputId": "0c469937-f2e1-47b8-c277-e89d225d3788",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from torch.backends import cudnn\n",
        "\n",
        "# By default, everything is loaded to cpu\n",
        "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "\n",
        "cudnn.benchmark # optimizes runtime"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42p5-7IN2UfG",
        "colab_type": "code",
        "outputId": "b5509b90-5d20-45c7-8eee-0ac16813ceb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "for epoch in range(NUM_EPOCHS):  # loop over the dataset multiple times\n",
        "  print(f'Epoch {epoch+1}/{NUM_EPOCHS}')\n",
        "  running_loss_m = 0.0\n",
        "  running_loss_p = 0.0\n",
        "  \n",
        "  source_data_iter = loopy(source_dataloader)\n",
        "  target_data_iter = loopy(target_dataloader)\n",
        "\n",
        "  for it in range(NUM_ITER):\n",
        "\n",
        "    # set to train and zero the parameter gradients\n",
        "    net.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # ************************\n",
        "    # SOURCE MAIN FORWARD PASS\n",
        "    # ************************\n",
        "    # unpack in RGB images, depth images and labels\n",
        "    rimgs, dimgs, labels = next(source_data_iter)\n",
        "\n",
        "    # Bring data over the device of choice\n",
        "    rimgs = rimgs.to(DEVICE)\n",
        "    dimgs = dimgs.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    # forward\n",
        "    outputs = net(rimgs, dimgs)\n",
        "    # compute main loss\n",
        "    loss_m = criterion(outputs, labels)\n",
        "    loss_m.backward()\n",
        "    \n",
        "    # ***************************\n",
        "    # SOURCE PRETEXT FORWARD PASS\n",
        "    # ***************************\n",
        "    # using same batch as main forward pass\n",
        "    rimgs, dimgs, labels = transform_batch(rimgs, dimgs)\n",
        "\n",
        "    rimgs = rimgs.to(DEVICE)\n",
        "    dimgs = dimgs.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    outputs = net(rimgs, dimgs, LAMBDA)\n",
        "    loss_sp = criterion(outputs, labels)\n",
        "    loss_sp.backward()\n",
        "\n",
        "    # ***************************\n",
        "    # TARGET PRETEXT FORWARD PASS\n",
        "    # ***************************\n",
        "\n",
        "    rimgs, dimgs, _ = next(target_data_iter)\n",
        "    rimgs, dimgs, labels = transform_batch(rimgs, dimgs)\n",
        "\n",
        "    rimgs = rimgs.to(DEVICE)\n",
        "    dimgs = dimgs.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    outputs = net(rimgs, dimgs, LAMBDA)\n",
        "\n",
        "    loss_tp = criterion(outputs, labels)\n",
        "    new_loss_tp = loss_tp + ENTROPY_WEIGHT * entropy_loss(outputs)\n",
        "    loss_tp.backward()\n",
        "\n",
        "    # update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    # print statistics\n",
        "    running_loss_m += loss_m.item()\n",
        "    running_loss_p += (loss_sp+loss_tp).item()\n",
        "    if it % 100 == 99:    # print every 100 mini-batches\n",
        "      print(f'[{epoch+1}, {it+1}] Lm {running_loss_m/100}, Lp {running_loss_p/100}')\n",
        "      running_loss_m = 0.\n",
        "      running_loss_p = 0.\n",
        "\n",
        "  scheduler.step()\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:100: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1, 100] Lm 3.8091703915596007, Lp 2.7908069014549257\n",
            "[1, 200] Lm 3.5794866490364075, Lp 2.7685572361946105\n",
            "[1, 300] Lm 3.4213844323158265, Lp 2.7333656263351442\n",
            "Epoch 2/3\n",
            "[2, 100] Lm 3.3092102885246275, Lp 2.6289972114562987\n",
            "[2, 200] Lm 3.271765897274017, Lp 2.574670310020447\n",
            "[2, 300] Lm 3.2418687200546263, Lp 2.5211207342147826\n",
            "Epoch 3/3\n",
            "[3, 100] Lm 3.1557154512405394, Lp 2.4438062715530395\n",
            "[3, 200] Lm 3.1421393084526064, Lp 2.3967542266845703\n",
            "[3, 300] Lm 3.1260405778884888, Lp 2.3421239352226255\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JX-CKajUS-Y",
        "colab_type": "text"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4Pl61fiVZYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_ratio(outputs, labels, current_ratio):\n",
        "  _, preds = torch.max(outputs.data, 1)\n",
        "  current_ratio[0] += torch.sum(labels.data == preds).data.item()\n",
        "  current_ratio[1] += preds.size(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9E9Y-gGUVAt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "881a5a48-7751-4154-9140-6808a033ea12"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "net.train(False) # Set Network to evaluation mode\n",
        "\n",
        "acc_ratio = [0, 0]\n",
        "for rimgs, dimgs, labels in tqdm(target_dataloader):\n",
        "  rimgs = rimgs.to(DEVICE)\n",
        "  dimgs = dimgs.to(DEVICE)\n",
        "  labels = labels.to(DEVICE)\n",
        "\n",
        "  outputs = net(rimgs, dimgs)\n",
        "  update_ratio(outputs, labels, acc_ratio)\n",
        "\n",
        "accuracy = acc_ratio[0] / acc_ratio[1]\n",
        "print(f'Test accuracy on target: {accuracy}')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/324 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:100: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "100%|██████████| 324/324 [02:55<00:00,  1.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy on target: 0.37993827160493826\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mdRgoIhdRJW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "1cce33db-e1ae-4c2d-df4a-9a9bc77428a8"
      },
      "source": [
        "net.to(DEVICE)\n",
        "net.train(False)\n",
        "for rimgs, dimgs, labels in target_dataloader:\n",
        "\n",
        "  rimgs = rimgs.to(DEVICE)\n",
        "  dimgs = dimgs.to(DEVICE)\n",
        "  o = net(rimgs, dimgs)\n",
        "  print(o.size())\n",
        "  break"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:100: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([100, 47])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}